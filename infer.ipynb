{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer,\n",
    "    HfArgumentParser,\n",
    ")\n",
    "from mamba.configuration_mamba import MambaConfig\n",
    "from mamba.modeling_mamba import MambaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371303424"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = \"modeloutput/checkpoint-4000\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "model = MambaForCausalLM.from_pretrained(model_name_or_path, device_map=\"cuda:0\")\n",
    "\n",
    "n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n",
    "n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <s>中国是全球最大的企业之一，是全球最大的企业之一，是全球最大的跨境电商企业，是全球最大的跨境电商企业，也是全球最大的跨境电商企业之一，是全球最大的跨境电商企业，是全球最大的跨境电商企业，是全球最大的跨境电商企业之一，是全球最大的跨境电商和跨境电商企业，是全球最大的跨境电商企业。\n",
      "B2B是跨境电商企业，在跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境电商、跨境\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"中国是\", return_tensors=\"pt\")\n",
    "inputs = inputs.to(model.device)\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    penalty_alpha=0.6,\n",
    "    temperature=0.9,\n",
    "    repetition_penalty=1.2,\n",
    ")\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt: str,\n",
    "    n_tokens_to_gen: int = 50,\n",
    "    sample: bool = True,\n",
    "    top_k: int = 10,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    for token_n in tqdm(range(n_tokens_to_gen)):\n",
    "        with torch.no_grad():\n",
    "            indices_to_input = input_ids\n",
    "            next_token_logits = model(indices_to_input).logits[:, -1]\n",
    "\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        (batch, vocab_size) = probs.shape\n",
    "\n",
    "        if top_k is not None:\n",
    "            (values, indices) = torch.topk(probs, k=top_k)\n",
    "            probs[probs < values[:, -1, None]] = 0\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "        if sample:\n",
    "            next_indices = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "\n",
    "        input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "\n",
    "    return output_completions\n",
    "\n",
    "\n",
    "print(generate(model, tokenizer, \"中国是\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(model, tokenizer, \"如何看待\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hz_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
